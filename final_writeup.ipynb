{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Final Project Reflection\n",
    "#### Justin Long and Austin Zang\n",
    "#### CS 181Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISION:\n",
    "- When we started the brainstorming process for this project, we had no idea where to begin! We had so many diverse CS-related interests that had been spurred by topics discussed inside and outside of class. We eventually realized that we could make something pretty cool by combining all of our shared interests through a CS lens. Both of us like virtual reality, both of us are basketball fans, and both of us like robots. So, we thought, how can we combine them all? We eventually figured it out: What if we trained a model to shoot a free throw in basketball in 3D? That was our initial vision that we stuck with until later in the project, where we realized that we accidentally trained a model to make a crazy trickshot in 3D. So, by the time of our presentation and the end of the project, that was our vision.\n",
    "- Another key facet of our vision was that even though we could have generated shots that would 100% go into the basket using physics, we used a neural net instead to simulate internal cognitive processees that occur when a real person tries to shoot a free throw, estimating the correct amount of power to give the shot once we decide on a starting angle. However, we did not take into account the most feasible starting velocities and angles for real people to use with their shots, which allowed our neural net to predict some outlandish shots to go in using velocities that go far beyond what a normal shot from a person would use and angles that sometimes even go in complete opposite directions as orthodox free throws, but it predicted that those shots would go in. Perhaps if humans did not have the bias of shooting a free throw regularly (a normal forward arc into the basket), we too would more evenly consider bouncing off the floor and walls to make the shot. So, while our final product did not entirely stick to our vision, our neural net's decisions are still explainable within the confides of cognition!\n",
    "\n",
    "PROGRESS:\n",
    "- We found a walkthrough online on how to use a reinforcement learning model (which is what we thought we'd need to \"teach\" the model to shoot a free throw) with a library called PyGame, which we used to simulate a 2D version of the shot. Unfortunately, the reinforcement learning model did not work out: it was taking far too long to run, and we had to start making some progess somehow. So, we shifted gears towards something we were more comfortable with: neural nets. We created a random 25000-shot dataset using the 2D simulation in PyGame that contained each shot's random starting velocity, starting angle, and whether the shot went in or not. Using this, we trained a neural net to predict whether a shot would go in or not given a starting angle and velocity. Then, for a given starting angle, we iterated over a wide range of starting velocities until we found a range of velocities for shots that our neural net said would go in. By taking the middle shot in this \"make\" range of velocities (which we dubbed \"the Midpoint Strategy\"), we were able to generate a shot that would go in virtually every single time. A key factor to this strategy is that the most optimal shot from the Midpoint Strategy was most often not a regular shot -- it usually bounced off the walls and ground (multiple times!), which we allowed it to do in the 2D simulation. So, instead of creating a free-throw simulator, our neural net was giving us crazy trickshots!\n",
    "- However, an issue we also repeatedly ran into was finding a way to translate our 2D shot into 3D. After looking around for awhile, the best 3D-modeling library we could find was called VPython (which is literally older than us; it came out in 2000). The problem with VPython is that it did not include any collision physics. We had to manually create realistic collision physics if we wanted our 3D simulation to look realistic. So, that's what we did. After hours of tinkering, we finally created a 3D simulator in VPython where a user feeds it a starting angle and velocity, and it creates a 3D simulation of the shot that (usually) mimics the 2D simulation pretty well. Unfortunately, a seamless translation between PyGame and VPython was not easy, and sometimes the shots still don't turn out the same, but we are happy with the immense progress we made.\n",
    "- By the end, we now have a working set of files where you can use the 2D simulator files (custom_environment, random_agent, and tuning) that utilize PyGame and a few other libraries to generate a shot in 2D using a starting velocity and angle, you can use the nn_angle_velocity_predictor file to predict whether a starting angle and velocity will result in a make, and you can use the 3D_simulator file to simulate the shot in 3D using VPython. Our shooter (who we have appropriately named PyChael Jordan) launches the ball from the desired starting angle with the desired starting velocity using necessary collision physics to ensure that we witness the correct shot.\n",
    "\n",
    "EXTENDING THE PROJECT FURTHER:\n",
    "- Another idea we had that we would have loved to be able to have implemented was creating another dataset where instead of just a clear shot at the hoop, what if there were some sort of barrier, such as wall or a defender? How would the neural nets have reacted to that? We think that would have been a very interesting part of our project if we had time and resources to do so.\n",
    "- We also wondered if there could be a way to create an interactive aspect of the project where the user attempts to create a better trickshot than the neural net (though we're not sure what \"better\" means here -- potentially you just want your trickshot to go in and the neural net's to miss, which is does sometimes do). \n",
    "- Also, we would have loved to create a more polished final product -- including a front end page that allows a user to access all three of our files from one place rather than having to jump back and forth across the different files -- perhaps hosting it on Flask for more accessibility and a better viewing experience. It also would have been super cool to somehow get a 3D simulation viewable on a VR headset. This would require us to probably record the 3D simulation, download it, upload it to a streaming platform, and view it on a headset from that platform (or some other method that we don't know about yet for how to view personal 3D content in VR). \n",
    "\n",
    "HOW WE'D DO IT DIFFERENTLY:\n",
    "- If we were to do this project again from scratch, we definitely wouldn't have devoted so much time into trying to get the reinforcement learning model to work (though it was certainly a learning experience for us!) and instead jump straight into neural nets. We also would have put more time into getting the transition between the 2D and 3D simulations to be more seamless, as that is probably the biggest problem with our final product. Another thing to keep in mind is that we ended up having to slightly alter our dataset of shots so that it had a roughly even number of makes and misses, so we ended up duplicating most of our makes to get there. Perhaps instead, we could have generated an even bigger dataset and just removed some of the misses to achieve this ratio. \n",
    "- Overall, even our difficulties along the way led to insightful learning moments for the two of us. So, if we truly had the opportunity to restart and do it all over again, we might not get the knowledge about reinforcement learning, neural nets, collision physics, 2D to 3D translations, and more that we have now because of this project. We had lots of fun and are incredibly happy with how it turned out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presentation link: https://docs.google.com/presentation/d/1uSXE5OeFBhA2rGpn7SxFO3Kwj3gJb4sRODeogDkgzTU/edit?usp=sharing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
